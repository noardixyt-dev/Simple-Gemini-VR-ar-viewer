<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Mirror Stereo AR</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.160.0/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.160.0/examples/js/loaders/GLTFLoader.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: sans-serif; }
        #ui { position: fixed; inset: 0; z-index: 100; display: flex; flex-direction: column; align-items: center; justify-content: center; background: #000; color: #00e5ff; }
        .btn { background: #00e5ff; color: #000; border: none; padding: 20px 50px; border-radius: 50px; font-weight: bold; cursor: pointer; margin-top: 20px; }
        input[type="file"] { display: none; }
    </style>
</head>
<body>

    <div id="ui">
        <h1>Ar Vr Viewer</h1>
        <label style="border: 2px dashed #00e5ff; padding: 20px; border-radius: 10px; cursor: pointer;">
            <span>üìÅ IMPORT .GLB MODEL</span>
            <input type="file" id="file-input" accept=".glb,.gltf">
        </label>
        <button class="btn" onclick="start()">START DUAL-VIEW</button>
    </div>

    <canvas id="c"></canvas>

    <script>
        let renderer, scene, camera, videoTexture, model, renderTarget;
        let finalScene, finalCamera;

        async function start() {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: 1280, height: 720 } 
            });
            const video = document.createElement('video');
            video.srcObject = stream;
            video.play();

            document.getElementById('ui').style.display = 'none';
            init(video);
        }

        function init(video) {
            const canvas = document.querySelector('#c');
            renderer = new THREE.WebGLRenderer({canvas, antialias: true});
            
            // 1. MASTER AR SCENE (Where tracking happens)
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(60, 1280/720, 0.1, 100);
            
            videoTexture = new THREE.VideoTexture(video);
            scene.background = videoTexture;

            // Master Lighting & Model
            scene.add(new THREE.HemisphereLight(0xffffff, 0x444444, 3));
            const box = new THREE.Mesh(new THREE.BoxGeometry(0.3, 0.3, 0.3), new THREE.MeshStandardMaterial({color: 0x00e5ff}));
            box.position.set(0, 0, -1.5);
            scene.add(box);
            model = box;

            // 2. OFF-SCREEN BUFFER (The "Mirror")
            renderTarget = new THREE.WebGLRenderTarget(1280, 720);

            // 3. FINAL SBS SCENE (The "Display")
            finalScene = new THREE.Scene();
            finalCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
            
            const material = new THREE.MeshBasicMaterial({ map: renderTarget.texture });
            // Left Eye Quad
            const leftQuad = new THREE.Mesh(new THREE.PlaneGeometry(1, 2), material);
            leftQuad.position.set(-0.5, 0, 0);
            finalScene.add(leftQuad);
            // Right Eye Quad (Exact Copy)
            const rightQuad = new THREE.Mesh(new THREE.PlaneGeometry(1, 2), material);
            rightQuad.position.set(0.5, 0, 0);
            finalScene.add(rightQuad);

            // File Importer
            document.getElementById('file-input').addEventListener('change', (e) => {
                const url = URL.createObjectURL(e.target.files[0]);
                new THREE.GLTFLoader().load(url, (gltf) => {
                    scene.remove(model);
                    model = gltf.scene;
                    model.position.set(0, 0, -1.5);
                    scene.add(model);
                });
            });

            // Gyro Tracking
            window.addEventListener('deviceorientation', (e) => {
                const alpha = THREE.MathUtils.degToRad(e.alpha);
                const beta = THREE.MathUtils.degToRad(e.beta);
                const gamma = THREE.MathUtils.degToRad(e.gamma);
                scene.rotation.set(beta, alpha, -gamma, 'YXZ');
            });

            render();
        }

        function render() {
            requestAnimationFrame(render);
            
            // Step A: Render the tracked AR scene to the mirror buffer
            renderer.setRenderTarget(renderTarget);
            renderer.render(scene, camera);
            
            // Step B: Render the mirror buffer twice to the screen
            renderer.setRenderTarget(null);
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.render(finalScene, finalCamera);
        }
    </script>
</body>
</html>

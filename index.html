<!DOCTYPE html>
<html>
<head>
    <title>Noardix Camera Solver</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        body { margin: 0; overflow: hidden; background: #000; }
        #ui { position: fixed; inset: 0; display: flex; align-items: center; justify-content: center; z-index: 100; background: rgba(0,0,0,0.5); color: white; }
        button { padding: 20px; border-radius: 50px; background: #00e5ff; border: none; font-weight: bold; cursor: pointer; }
    </style>
</head>
<body>
    <div id="ui"><button id="btn">ENGAGE CAMERA TRACKER</button></div>
    <script type="module">
        let renderer, scene, camLeft, camRight, bgScene, bgCam, video, videoTexture;
        let canvas, ctx, prevData;
        let virtualCamPos = new THREE.Vector3(0, 0, 0);
        let gyroRot = new THREE.Quaternion();

        async function start() {
            // 1. Capture Camera
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
            video = document.createElement('video');
            video.srcObject = stream;
            await video.play();

            // 2. Setup "Tracking Canvas" (Invisible)
            canvas = document.createElement('canvas');
            canvas.width = 64; canvas.height = 48; // Tiny resolution = Ultra fast tracking
            ctx = canvas.getContext('2d');

            // 3. Three.js Engine
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.autoClear = false;
            document.body.appendChild(renderer.domElement);

            // Background (The "Real" World)
            videoTexture = new THREE.VideoTexture(video);
            bgScene = new THREE.Scene();
            bgCam = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
            bgScene.add(new THREE.Mesh(new THREE.PlaneGeometry(2, 2), new THREE.MeshBasicMaterial({ map: videoTexture })));

            // Foreground (The "Virtual" World)
            scene = new THREE.Scene();
            const aspect = (window.innerWidth / 2) / window.innerHeight;
            camLeft = new THREE.PerspectiveCamera(70, aspect, 0.1, 1000);
            camRight = new THREE.PerspectiveCamera(70, aspect, 0.1, 1000);

            const object = new THREE.Mesh(new THREE.IcosahedronGeometry(0.3, 0), new THREE.MeshNormalMaterial({wireframe: true}));
            object.position.set(0, 0, -2);
            scene.add(object);

            // 4. Sensors
            window.addEventListener('deviceorientation', e => {
                const euler = new THREE.Euler(THREE.MathUtils.degToRad(e.beta), THREE.MathUtils.degToRad(e.alpha), -THREE.MathUtils.degToRad(e.gamma), 'YXZ');
                gyroRot.setFromEuler(euler);
            });

            loop();
        }

        function solveMovement() {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const currData = ctx.getImageData(0, 0, canvas.width, canvas.height).data;
            
            if (prevData) {
                let shiftX = 0, shiftY = 0, weight = 0;
                for (let i = 0; i < currData.length; i += 16) { // Sample pixels
                    const diff = currData[i] - prevData[i];
                    if (Math.abs(diff) > 20) {
                        const x = (i / 4) % canvas.width;
                        const y = Math.floor((i / 4) / canvas.width);
                        shiftX += (x - canvas.width/2);
                        shiftY += (y - canvas.height/2);
                        weight++;
                    }
                }
                if (weight > 10) {
                    // Match the virtual camera movement to the pixel movement
                    virtualCamPos.x += (shiftX / weight) * 0.001;
                    virtualCamPos.y -= (shiftY / weight) * 0.001;
                }
            }
            prevData = currData;
        }

        function loop() {
            requestAnimationFrame(loop);
            solveMovement(); // THE MATCHER

            [camLeft, camRight].forEach((c, i) => {
                c.quaternion.copy(gyroRot);
                c.position.copy(virtualCamPos);
                c.translateX(i === 0 ? -0.03 : 0.03);
            });

            const w = window.innerWidth, h = window.innerHeight;
            renderer.setScissorTest(true);
            // Left Eye
            renderer.setViewport(0, 0, w/2, h); renderer.setScissor(0, 0, w/2, h);
            renderer.clear(); renderer.render(bgScene, bgCam); renderer.render(scene, camLeft);
            // Right Eye
            renderer.setViewport(w/2, 0, w/2, h); renderer.setScissor(w/2, 0, w/2, h);
            renderer.render(bgScene, bgCam); renderer.render(scene, camRight);
        }

        document.getElementById('btn').onclick = () => { document.getElementById('ui').remove(); start(); };
    </script>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Alva 6DoF Stereo Engine</title>
    <script src="https://cdn.jsdelivr.net/gh/alvacoda/alva_ar@main/dist/alva_ar.js"></script>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; }
        #ui { position: absolute; z-index: 10; padding: 20px; color: #00e5ff; }
        .lens { position: absolute; border: 2px solid rgba(0,229,255,0.3); border-radius: 50%; overflow: hidden; }
    </style>
</head>
<body>
    <div id="ui">
        <label style="background:#00e5ff; color:#000; padding:10px; border-radius:5px; font-weight:bold;">
            LOAD GLB <input type="file" id="file" accept=".glb" style="display:none">
        </label>
        <p id="status">Scanning Floor...</p>
    </div>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';

        let scene, renderer, video, alva, model;
        let cameraL, cameraR; 
        const IPD = 0.064; // Standard eye separation in meters

        async function init() {
            // 1. Start Camera
            video = document.createElement('video');
            video.srcObject = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: 720, height: 720 } 
            });
            await video.play();

            // 2. Setup AlvaAR (SLAM)
            const config = { width: 720, height: 720 };
            alva = await AlvaAR.Initialize(config);

            // 3. Three.js Core
            scene = new THREE.Scene();
            scene.add(new THREE.HemisphereLight(0xffffff, 0x444444, 3));

            // Two Cameras for True Depth
            cameraL = new THREE.PerspectiveCamera(75, 1, 0.1, 100);
            cameraR = new THREE.PerspectiveCamera(75, 1, 0.1, 100);

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.autoClear = false;
            document.body.appendChild(renderer.domElement);

            // 4. Background Video Plane
            const bgGeo = new THREE.PlaneGeometry(2, 2);
            const videoTex = new THREE.VideoTexture(video);
            const bgMat = new THREE.MeshBasicMaterial({ map: videoTex, depthTest: false });
            const bg = new THREE.Mesh(bgGeo, bgMat);
            bg.scale.set(10, 10, 1);
            bg.position.z = -5;
            scene.add(bg);

            loop();
        }

        function loop() {
            requestAnimationFrame(loop);

            // --- TRACKING STEP ---
            const pose = alva.findCameraPose(video); // SLAM calculates 6DoF position
            if (pose) {
                const mat = new THREE.Matrix4().fromArray(pose);
                
                // Update Left Eye
                cameraL.matrixWorld.copy(mat);
                cameraL.translateX(-IPD / 2);
                cameraL.matrixWorldInverse.copy(cameraL.matrixWorld).invert();

                // Update Right Eye
                cameraR.matrixWorld.copy(mat);
                cameraR.translateX(IPD / 2); // Physical shift for depth
                cameraR.matrixWorldInverse.copy(cameraR.matrixWorld).invert();
            }

            // --- RENDERING STEP (Stereo + Rounded Viewports) ---
            const w = window.innerWidth, h = window.innerHeight;
            const size = Math.min(w/2, h) * 0.9;
            
            renderer.clear();

            // Render Left Eye (Scissor to circle-ish area)
            renderer.setViewport(w/4 - size/2, h/2 - size/2, size, size);
            renderer.setScissor(w/4 - size/2, h/2 - size/2, size, size);
            renderer.setScissorTest(true);
            renderer.render(scene, cameraL);

            // Render Right Eye
            renderer.setViewport(3*w/4 - size/2, h/2 - size/2, size, size);
            renderer.setScissor(3*w/4 - size/2, h/2 - size/2, size, size);
            renderer.render(scene, cameraR);
        }

        document.getElementById('file').onchange = (e) => {
            const reader = new FileReader();
            reader.onload = (ev) => {
                new GLTFLoader().parse(ev.target.result, '', (gltf) => {
                    if(model) scene.remove(model);
                    model = gltf.scene;
                    model.position.set(0, 0, -2);
                    scene.add(model);
                });
            };
            reader.readAsArrayBuffer(e.target.files[0]);
        };

        init();
    </script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Noardix Stereo AR Viewer</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <style>
        body { margin: 0; overflow: hidden; background: #000; }
        #ui { position: fixed; top: 10px; left: 50%; transform: translateX(-50%); z-index: 1000; display: flex; gap: 10px; }
        button { background: #00e5ff; border: none; padding: 15px; border-radius: 10px; font-weight: bold; }
        #lens-mask {
            position: fixed; inset: 0; pointer-events: none; z-index: 500;
            background: radial-gradient(circle at 25% 50%, transparent 35%, black 65%),
                        radial-gradient(circle at 75% 50%, transparent 35%, black 65%);
        }
        /* Lock Landscape Prompt */
        #warning { position: fixed; inset: 0; background: black; color: white; z-index: 2000; display: flex; align-items: center; justify-content: center; visibility: visible; }
        @media screen and (orientation: landscape) { #warning { visibility: hidden; } }
    </style>
</head>
<body>
    <div id="warning"><h1>PLEASE ROTATE TO LANDSCAPE</h1></div>
    <div id="ui">
        <button id="start-btn">1. START VR-AR</button>
        <button onclick="document.getElementById('file-input').click()">2. IMPORT .GLB</button>
        <input type="file" id="file-input" accept=".glb" style="display:none">
    </div>
    <div id="lens-mask"></div>

    <script type="module">
        let renderer, scene, camera, model, videoTexture, renderTarget, finalScene, finalCamera;

        async function init() {
            const canvas = document.createElement('canvas');
            renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // 1. THE AR BRAIN
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            
            // LIGHTING
            scene.add(new THREE.HemisphereLight(0xffffff, 0x444444, 3));

            // 2. MANUAL CAMERA FEED (Fixes the black screen)
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } } 
            });
            const video = document.createElement('video');
            video.srcObject = stream;
            video.play();
            videoTexture = new THREE.VideoTexture(video);
            
            // Create a background plane that stays behind the 3D model
            const bgGeo = new THREE.PlaneGeometry(20, 10);
            const bgMat = new THREE.MeshBasicMaterial({ map: videoTexture });
            const bgMesh = new THREE.Mesh(bgGeo, bgMat);
            bgMesh.position.set(0, 0, -5); // Keep it behind the model
            camera.add(bgMesh); // Attach to camera so it follows your movement
            scene.add(camera);

            // 3. THE STEREO MIRROR
            renderTarget = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight);
            finalScene = new THREE.Scene();
            finalCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
            const mirrorMat = new THREE.MeshBasicMaterial({ map: renderTarget.texture });
            
            const leftEye = new THREE.Mesh(new THREE.PlaneGeometry(1, 2), mirrorMat);
            leftEye.position.set(-0.5, 0, 0);
            finalScene.add(leftEye);

            const rightEye = new THREE.Mesh(new THREE.PlaneGeometry(1, 2), mirrorMat);
            rightEye.position.set(0.5, 0, 0);
            finalScene.add(rightEye);

            // GYRO TRACKING
            window.addEventListener('deviceorientation', (e) => {
                const alpha = THREE.MathUtils.degToRad(e.alpha);
                const beta = THREE.MathUtils.degToRad(e.beta);
                const gamma = THREE.MathUtils.degToRad(e.gamma);
                camera.rotation.set(beta, alpha, -gamma, 'YXZ');
            });

            // LOAD MODEL
            document.getElementById('file-input').addEventListener('change', (e) => {
                const url = URL.createObjectURL(e.target.files[0]);
                new THREE.GLTFLoader().load(url, (gltf) => {
                    if (model) scene.remove(model);
                    model = gltf.scene;
                    model.position.set(0, -1.6, -3); // Pin to "floor"
                    scene.add(model);
                });
            });

            animate();
        }

        function animate() {
            requestAnimationFrame(animate);
            // Draw everything to the mirror buffer
            renderer.setRenderTarget(renderTarget);
            renderer.render(scene, camera);
            // Draw that mirror to the screen side-by-side
            renderer.setRenderTarget(null);
            renderer.render(finalScene, finalCamera);
        }

        document.getElementById('start-btn').addEventListener('click', () => {
            init();
            document.getElementById('ui').style.display = 'none';
        });
    </script>
</body>
</html>

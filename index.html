<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Fixed Alva 6DoF Stereo</title>
    <script src="https://cdn.jsdelivr.net/gh/alvacoda/alvacoda_ar@1.0.0/dist/alva_ar.js"></script>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: sans-serif; }
        #overlay { position: absolute; z-index: 100; top: 0; left: 0; width: 100%; height: 100%; background: #000; display: flex; align-items: center; justify-content: center; }
        .btn { background: #00e5ff; color: #000; padding: 20px; border-radius: 10px; font-weight: bold; cursor: pointer; border: none; }
    </style>
</head>
<body>
    <div id="overlay"><button class="btn" id="startBtn">START AR ENGINE</button></div>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';

        let alva, scene, renderer, video, model, videoTex;
        let cameraL, cameraR;
        const IPD = 0.064; // Distance between eyes

        async function init() {
            // 1. Camera setup with explicit wait
            video = document.createElement('video');
            video.setAttribute('autoplay', '');
            video.setAttribute('muted', '');
            video.setAttribute('playsinline', '');
            
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } } 
            });
            video.srcObject = stream;
            
            // Wait for video to actually start playing
            await new Promise((resolve) => video.onloadedmetadata = resolve);
            video.play();

            // 2. Initialize AlvaAR SLAM
            // We use the video dimensions for the tracker
            alva = await AlvaAR.Initialize(video.videoWidth, video.videoHeight);

            // 3. Three.js Setup
            scene = new THREE.Scene();
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.autoClear = false;
            document.body.appendChild(renderer.domElement);

            // Stereoscopic Cameras
            const aspect = (window.innerWidth / 2) / window.innerHeight;
            cameraL = new THREE.PerspectiveCamera(75, aspect, 0.1, 1000);
            cameraR = new THREE.PerspectiveCamera(75, aspect, 0.1, 1000);

            // Background Video Feed (Must be visible in both eyes)
            videoTex = new THREE.VideoTexture(video);
            const bgGeo = new THREE.PlaneGeometry(2, 2);
            const bgMat = new THREE.MeshBasicMaterial({ map: videoTex, depthTest: false });
            const bg = new THREE.Mesh(bgGeo, bgMat);
            bg.scale.set(10, 10, 1);
            bg.position.z = -5; // Far back
            scene.add(bg);

            scene.add(new THREE.HemisphereLight(0xffffff, 0x444444, 3));

            // Load a default model (Damaged Helmet)
            new GLTFLoader().load('https://threejs.org/examples/models/gltf/DamagedHelmet/glTF/DamagedHelmet.gltf', (gltf) => {
                model = gltf.scene;
                model.position.set(0, 0, -2); // 2 meters in front
                scene.add(model);
            });

            animate();
            document.getElementById('overlay').style.display = 'none';
        }

        function animate() {
            requestAnimationFrame(animate);

            // Tracker Step
            const pose = alva.findCameraPose(video);
            if (pose) {
                const mat = new THREE.Matrix4().fromArray(pose);
                
                // Update Left Eye Perspective
                cameraL.matrixWorld.copy(mat);
                cameraL.translateX(-IPD / 2);
                cameraL.matrixWorldInverse.copy(cameraL.matrixWorld).invert();

                // Update Right Eye Perspective
                cameraR.matrixWorld.copy(mat);
                cameraR.translateX(IPD / 2);
                cameraR.matrixWorldInverse.copy(cameraR.matrixWorld).invert();
            }

            // Rendering Step
            const w = window.innerWidth;
            const h = window.innerHeight;

            renderer.clear();

            // Render Left Viewport
            renderer.setViewport(0, 0, w / 2, h);
            renderer.render(scene, cameraL);

            // Render Right Viewport
            renderer.setViewport(w / 2, 0, w / 2, h);
            renderer.render(scene, cameraR);
        }

        document.getElementById('startBtn').onclick = init;
    </script>
</body>
</html>

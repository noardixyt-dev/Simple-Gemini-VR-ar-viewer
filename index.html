<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Noardix Dual-Eye AR</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.160.0/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.160.0/examples/js/loaders/GLTFLoader.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; }
        #ui { position: fixed; top: 10px; left: 10px; z-index: 100; display: flex; gap: 5px; }
        button { background: #00e5ff; border: none; padding: 10px; border-radius: 5px; font-weight: bold; }
        /* The Cardboard Lens Mask */
        #lens-mask {
            position: fixed; inset: 0; pointer-events: none; z-index: 50;
            background: radial-gradient(circle at 25% 50%, transparent 35%, black 65%),
                        radial-gradient(circle at 75% 50%, transparent 35%, black 65%);
        }
    </style>
</head>
<body>

    <div id="ui">
        <button onclick="document.getElementById('file-input').click()">üìÅ IMPORT GLB</button>
        <input type="file" id="file-input" accept=".glb" style="display:none">
        <span style="color:white; font-size: 12px; margin-left: 10px;">Place phone in Cardboard</span>
    </div>

    <div id="lens-mask"></div>
    <canvas id="c"></canvas>

    <script>
        let renderer, scene, camera, model, videoTexture, renderTarget;
        let finalScene, finalCamera;

        async function init() {
            const canvas = document.querySelector('#c');
            renderer = new THREE.WebGLRenderer({canvas, antialias: true});
            renderer.setSize(window.innerWidth, window.innerHeight);

            // 1. THE AR SCENE (The "Brain")
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 100);
            
            // Get Real World Camera
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: 1280, height: 720 } 
            });
            const video = document.createElement('video');
            video.srcObject = stream;
            video.play();
            videoTexture = new THREE.VideoTexture(video);
            scene.background = videoTexture;

            scene.add(new THREE.HemisphereLight(0xffffff, 0x444444, 3));

            // 2. THE CLONING BUFFER (The "Mirror")
            renderTarget = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight);

            // 3. THE DISPLAY SCENE (The "Eyes")
            finalScene = new THREE.Scene();
            finalCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
            const material = new THREE.MeshBasicMaterial({ map: renderTarget.texture });
            
            const leftEye = new THREE.Mesh(new THREE.PlaneGeometry(1, 2), material);
            leftEye.position.set(-0.5, 0, 0);
            finalScene.add(leftEye);

            const rightEye = new THREE.Mesh(new THREE.PlaneGeometry(1, 2), material);
            rightEye.position.set(0.5, 0, 0);
            finalScene.add(rightEye);

            // Import GLB Logic
            document.getElementById('file-input').addEventListener('change', (e) => {
                const url = URL.createObjectURL(e.target.files[0]);
                new THREE.GLTFLoader().load(url, (gltf) => {
                    if (model) scene.remove(model);
                    model = gltf.scene;
                    model.position.set(0, -1.6, -3); // Placed on "floor"
                    scene.add(model);
                });
            });

            // Gyroscope tracking (The "World Lock")
            window.addEventListener('deviceorientation', (e) => {
                const alpha = THREE.MathUtils.degToRad(e.alpha);
                const beta = THREE.MathUtils.degToRad(e.beta);
                const gamma = THREE.MathUtils.degToRad(e.gamma);
                camera.rotation.set(beta, alpha, -gamma, 'YXZ');
            });

            animate();
        }

        function animate() {
            requestAnimationFrame(animate);
            // Draw the AR tracking once to the buffer
            renderer.setRenderTarget(renderTarget);
            renderer.render(scene, camera);
            // Show that buffer in both eyes
            renderer.setRenderTarget(null);
            renderer.render(finalScene, finalCamera);
        }

        init();
    </script>
</body>
</html>

